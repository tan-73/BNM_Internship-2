{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58f604cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models, callbacks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2775128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32') / 255.0\n",
    "x_test  = x_test.reshape(-1,28,28,1).astype('float32') / 255.0\n",
    "\n",
    "y_train_oh = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_oh  = tf.keras.utils.to_categorical(y_test,  num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e73d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),  \n",
    "\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
      "Epoch 1/50\n",
      "211/211 [==============================] - 5s 19ms/step - loss: 0.9623 - accuracy: 0.9329 - val_loss: 3.1037 - val_accuracy: 0.1050 - lr: 0.0100\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0095.\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.8126 - accuracy: 0.9806 - val_loss: 1.1953 - val_accuracy: 0.8562 - lr: 0.0095\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.009025.\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7920 - accuracy: 0.9864 - val_loss: 0.7736 - val_accuracy: 0.9888 - lr: 0.0090\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.00857375.\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.7816 - accuracy: 0.9889 - val_loss: 0.7431 - val_accuracy: 0.9902 - lr: 0.0086\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0081450625.\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7752 - accuracy: 0.9903 - val_loss: 0.7389 - val_accuracy: 0.9910 - lr: 0.0081\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.007737809374999998.\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.7702 - accuracy: 0.9910 - val_loss: 0.7354 - val_accuracy: 0.9915 - lr: 0.0077\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.007350918906249998.\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7657 - accuracy: 0.9925 - val_loss: 0.7360 - val_accuracy: 0.9910 - lr: 0.0074\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.006983372960937498.\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7629 - accuracy: 0.9928 - val_loss: 0.7340 - val_accuracy: 0.9920 - lr: 0.0070\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.006634204312890623.\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7601 - accuracy: 0.9934 - val_loss: 0.7324 - val_accuracy: 0.9915 - lr: 0.0066\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.006302494097246091.\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7584 - accuracy: 0.9939 - val_loss: 0.7299 - val_accuracy: 0.9920 - lr: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.005987369392383787.\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7564 - accuracy: 0.9943 - val_loss: 0.7303 - val_accuracy: 0.9920 - lr: 0.0060\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.005688000922764597.\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7547 - accuracy: 0.9946 - val_loss: 0.7293 - val_accuracy: 0.9925 - lr: 0.0057\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.005403600876626367.\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7534 - accuracy: 0.9951 - val_loss: 0.7292 - val_accuracy: 0.9918 - lr: 0.0054\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.005133420832795048.\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7521 - accuracy: 0.9950 - val_loss: 0.7266 - val_accuracy: 0.9922 - lr: 0.0051\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0048767497911552955.\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7513 - accuracy: 0.9952 - val_loss: 0.7269 - val_accuracy: 0.9938 - lr: 0.0049\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00463291230159753.\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7503 - accuracy: 0.9958 - val_loss: 0.7283 - val_accuracy: 0.9925 - lr: 0.0046\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0044012666865176535.\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7497 - accuracy: 0.9958 - val_loss: 0.7261 - val_accuracy: 0.9933 - lr: 0.0044\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.004181203352191771.\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7482 - accuracy: 0.9964 - val_loss: 0.7255 - val_accuracy: 0.9928 - lr: 0.0042\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.003972143184582182.\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7474 - accuracy: 0.9964 - val_loss: 0.7257 - val_accuracy: 0.9930 - lr: 0.0040\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0037735360253530726.\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7473 - accuracy: 0.9960 - val_loss: 0.7250 - val_accuracy: 0.9927 - lr: 0.0038\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0035848592240854188.\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7464 - accuracy: 0.9959 - val_loss: 0.7253 - val_accuracy: 0.9927 - lr: 0.0036\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.003405616262881148.\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7459 - accuracy: 0.9964 - val_loss: 0.7239 - val_accuracy: 0.9932 - lr: 0.0034\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0032353354497370902.\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7454 - accuracy: 0.9967 - val_loss: 0.7235 - val_accuracy: 0.9935 - lr: 0.0032\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.003073568677250236.\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7447 - accuracy: 0.9966 - val_loss: 0.7236 - val_accuracy: 0.9930 - lr: 0.0031\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.002919890243387724.\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - 3s 17ms/step - loss: 0.7446 - accuracy: 0.9969 - val_loss: 0.7239 - val_accuracy: 0.9930 - lr: 0.0029\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.002773895731218338.\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7441 - accuracy: 0.9969 - val_loss: 0.7235 - val_accuracy: 0.9938 - lr: 0.0028\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0026352009446574203.\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7436 - accuracy: 0.9972 - val_loss: 0.7234 - val_accuracy: 0.9933 - lr: 0.0026\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.002503440897424549.\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7433 - accuracy: 0.9972 - val_loss: 0.7230 - val_accuracy: 0.9935 - lr: 0.0025\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0023782688525533216.\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7431 - accuracy: 0.9973 - val_loss: 0.7229 - val_accuracy: 0.9933 - lr: 0.0024\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0022593554099256557.\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7427 - accuracy: 0.9973 - val_loss: 0.7224 - val_accuracy: 0.9933 - lr: 0.0023\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0021463876394293728.\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7423 - accuracy: 0.9975 - val_loss: 0.7222 - val_accuracy: 0.9937 - lr: 0.0021\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0020390682574579037.\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7424 - accuracy: 0.9973 - val_loss: 0.7226 - val_accuracy: 0.9935 - lr: 0.0020\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0019371148445850087.\n",
      "Epoch 33/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7421 - accuracy: 0.9976 - val_loss: 0.7219 - val_accuracy: 0.9935 - lr: 0.0019\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0018402591023557583.\n",
      "Epoch 34/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7417 - accuracy: 0.9975 - val_loss: 0.7220 - val_accuracy: 0.9935 - lr: 0.0018\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0017482461472379703.\n",
      "Epoch 35/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7417 - accuracy: 0.9976 - val_loss: 0.7222 - val_accuracy: 0.9932 - lr: 0.0017\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0016608338398760717.\n",
      "Epoch 36/50\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.7413 - accuracy: 0.9976 - val_loss: 0.7220 - val_accuracy: 0.9935 - lr: 0.0017\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.001577792147882268.\n",
      "Epoch 37/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7409 - accuracy: 0.9977 - val_loss: 0.7213 - val_accuracy: 0.9938 - lr: 0.0016\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0014989025404881545.\n",
      "Epoch 38/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7409 - accuracy: 0.9977 - val_loss: 0.7219 - val_accuracy: 0.9937 - lr: 0.0015\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0014239574134637467.\n",
      "Epoch 39/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7408 - accuracy: 0.9976 - val_loss: 0.7218 - val_accuracy: 0.9932 - lr: 0.0014\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0013527595427905593.\n",
      "Epoch 40/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7403 - accuracy: 0.9978 - val_loss: 0.7216 - val_accuracy: 0.9935 - lr: 0.0014\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 0.0012851215656510312.\n",
      "Epoch 41/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7407 - accuracy: 0.9979 - val_loss: 0.7213 - val_accuracy: 0.9938 - lr: 0.0013\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 0.0012208654873684796.\n",
      "Epoch 42/50\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.7402 - accuracy: 0.9978 - val_loss: 0.7212 - val_accuracy: 0.9940 - lr: 0.0012\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 0.0011598222130000556.\n",
      "Epoch 43/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7401 - accuracy: 0.9980 - val_loss: 0.7214 - val_accuracy: 0.9935 - lr: 0.0012\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 0.0011018311023500529.\n",
      "Epoch 44/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7401 - accuracy: 0.9976 - val_loss: 0.7212 - val_accuracy: 0.9935 - lr: 0.0011\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 0.0010467395472325502.\n",
      "Epoch 45/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7397 - accuracy: 0.9980 - val_loss: 0.7213 - val_accuracy: 0.9935 - lr: 0.0010\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 0.0009944025698709225.\n",
      "Epoch 46/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7398 - accuracy: 0.9977 - val_loss: 0.7211 - val_accuracy: 0.9935 - lr: 9.9440e-04\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 0.0009446824413773763.\n",
      "Epoch 47/50\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.7398 - accuracy: 0.9979 - val_loss: 0.7212 - val_accuracy: 0.9937 - lr: 9.4468e-04\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 0.0008974483193085076.\n",
      "Epoch 48/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7396 - accuracy: 0.9977 - val_loss: 0.7212 - val_accuracy: 0.9933 - lr: 8.9745e-04\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 0.000852575903343082.\n",
      "Epoch 49/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7394 - accuracy: 0.9979 - val_loss: 0.7210 - val_accuracy: 0.9935 - lr: 8.5258e-04\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 0.000809947108175928.\n",
      "Epoch 50/50\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.7398 - accuracy: 0.9979 - val_loss: 0.7209 - val_accuracy: 0.9938 - lr: 8.0995e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce99ba8d30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.95, nesterov=True)\n",
    "lr_schedule1 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
    "lr_schedule2 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.01 * 0.95**epoch, verbose=1)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.15)\n",
    "\n",
    "\n",
    "model = build_cnn()\n",
    "model.compile(optimizer=optimizer, loss=loss_fn , metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train_oh, epochs=50, batch_size=256, validation_split=0.1, callbacks=[lr_schedule2, early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6c80728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.7234 - accuracy: 0.9934\n",
      "Test accuracy: 99.34\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test_oh)\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
